{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN27x/cU02Zya3Dodks+Dt0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rr715XwIBf6y","executionInfo":{"status":"ok","timestamp":1723708637747,"user_tz":-120,"elapsed":297,"user":{"displayName":"Giuseppe Piccolo","userId":"17844279195123924050"}},"outputId":"3a7160b3-b26c-4b41-b5de-58fcc2b7143e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Softmax numpy: [0.65900114 0.24243297 0.09856589]\n","tensor([0.6590, 0.2424, 0.0986])\n"]}],"source":["import torch\n","import numpy as np\n","import torch.nn as nn\n","\n","\n","def softmax(x):\n","  return np.exp(x) / np.sum(np.exp(x), axis=0)\n","\n","\n","x = np.array([2.0, 1.0, 0.1])\n","outputs = softmax(x)\n","print(\"Softmax numpy:\", outputs)\n","\n","x = torch.tensor([2.0, 1.0, 0.1])\n","outputs = torch.softmax(x, dim=0)\n","print(outputs)\n","\n","\n","def cross_entropy(actual, predicted):\n","  loss = -np.sum(actual * np.log(predicted))\n","  return loss\n","\n","\n","y = np.array([1, 0, 0])\n","y_pred_good = np.array([0.7, 0.2, 0.1])\n","y_pred_bad = np.array([0.1, 0.3, 0.6])\n","l1 = cross_entropy(y, y_pred_good)\n","l2 = cross_entropy(y, y_pred_bad)\n","print(f\"Loss1 numpy: {l1:.4f}\")\n","print(f\"Loss2 numpy: {l2:.4f}\")\n","\n","\n"]}]}