{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZUCHsfgEj3CjOzn4pBw7o"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"--c-j1oQN0A7","executionInfo":{"status":"ok","timestamp":1723628521393,"user_tz":-120,"elapsed":432,"user":{"displayName":"Giuseppe Piccolo","userId":"17844279195123924050"}},"outputId":"df49371b-4c30-4fe8-b9f0-87b8a77871d5"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1., grad_fn=<PowBackward0>)\n","tensor(-2.)\n"]}],"source":["import torch\n","\n","x = torch.tensor(1.0)\n","y = torch.tensor(2.0)\n","w = torch.tensor(1.0, requires_grad=True)\n","\n","#forward pass and compute the loss\n","y_hat = w * x\n","loss = (y_hat - y) ** 2\n","print(loss)\n","\n","#backward pass\n","loss.backward()\n","print(w.grad)\n","\n","#update weights\n","#next forward and backward\n"]}]}